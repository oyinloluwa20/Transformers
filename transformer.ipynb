{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'2.0.1+cpu'"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import torch\n",
                "from torch import nn\n",
                "import math\n",
                "torch.__version__"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "cpu\n"
                    ]
                }
            ],
            "source": [
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Hyperparameters\n",
                "num_heads = 8\n",
                "embed_len = 512\n",
                "batch_size = 8\n",
                "stack_len = 6\n",
                "dropout = 0.1\n",
                "\n",
                "output_vocab_size = 7000 #just for testing\n",
                "input_vocab_size = 7000 #just for testing"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Bulid the embedding block"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "class InputEmbedding(nn.Module):\n",
                "    def __init__(self, input_vocab_size = input_vocab_size, embed_len = embed_len, dropout = dropout, device = device) -> None:\n",
                "        super(InputEmbedding, self).__init__()\n",
                "        self.input_vocab_size = input_vocab_size\n",
                "        self.embed_len = embed_len\n",
                "        self.dropout = dropout\n",
                "\n",
                "        self.firstEmbedding = nn.Embedding(self.input_vocab_size, self.embed_len)\n",
                "        self.secondEmbedding = nn.Embedding(self.input_vocab_size, self.embed_len)\n",
                "        self.dropoutLayer = nn.Dropout()\n",
                "\n",
                "    def forward(self, input):\n",
                "        first_embedding = self.firstEmbedding(input)\n",
                "        batch_size, seq_len = input.shape\n",
                "\n",
                "        positions_vector = torch.arange(0, seq_len).expand(batch_size, seq_len).to(self.device)\n",
                "        positional_encoding = self.secondEmbedding(positions_vector)\n",
                "\n",
                "        return self.dropoutLayer(first_embedding + positional_encoding)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "ename": "AttributeError",
                    "evalue": "'InputEmbedding' object has no attribute 'device'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(\u001b[39m10\u001b[39m, (\u001b[39m8\u001b[39m, \u001b[39m20\u001b[39m))\n\u001b[0;32m      2\u001b[0m embedding \u001b[39m=\u001b[39m InputEmbedding()\n\u001b[1;32m----> 3\u001b[0m ouput \u001b[39m=\u001b[39m embedding\u001b[39m.\u001b[39;49mforward(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(output)\n",
                        "Cell \u001b[1;32mIn[22], line 16\u001b[0m, in \u001b[0;36mInputEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     13\u001b[0m first_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirstEmbedding(\u001b[39minput\u001b[39m)\n\u001b[0;32m     14\u001b[0m batch_size, seq_len \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape\n\u001b[1;32m---> 16\u001b[0m positions_vector \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, seq_len)\u001b[39m.\u001b[39mexpand(batch_size, seq_len)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m     17\u001b[0m positional_encoding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msecondEmbedding(positions_vector)\n\u001b[0;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropoutLayer(first_embedding \u001b[39m+\u001b[39m positional_encoding)\n",
                        "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
                        "\u001b[1;31mAttributeError\u001b[0m: 'InputEmbedding' object has no attribute 'device'"
                    ]
                }
            ],
            "source": [
                "input = torch.randint(10, (8, 20)).to(device)\n",
                "embedding = InputEmbedding().to(device)\n",
                "ouput = embedding.forward(input)\n",
                "print(output)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
